{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e5af194",
   "metadata": {},
   "source": [
    "For this hands-on, we will be using the [Power Plant dataset](https://archive.ics.uci.edu/ml/datasets/Combined+Cycle+Power+Plant) dataset where the goal is to predict the net hourly electrical energy output (PE) of a plant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb0ca7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc17a41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/power_plants.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e75d048",
   "metadata": {},
   "source": [
    "# MLflow Tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cccb836",
   "metadata": {},
   "source": [
    "## Model traning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e8b848",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_df, max_depth=2):\n",
    "    # Split data\n",
    "    X = train_df[[\"AT\", \"V\", \"AP\", \"RH\"]]\n",
    "    y = train_df[\"PE\"]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Fit model\n",
    "    model = RandomForestRegressor(max_depth=max_depth)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate the model\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "    print(f\"Test mse = {mse:.2f}, Test RMSE = {rmse:.2f}, Random forest max depth = {max_depth}\")\n",
    "    return model, mse, rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b848a073",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = train_model(df, max_depth=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31aa36d",
   "metadata": {},
   "source": [
    "- Test with different max depths for the Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22b5c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for max_depth in range(2, 7, 2):\n",
    "    _ = train_model(df, max_depth=max_depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfecbcd",
   "metadata": {},
   "source": [
    "## Experiment tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5ac419",
   "metadata": {},
   "source": [
    "### Some vocabulary:\n",
    "- **run**: single execution of model training code. Each run can record different informations (model parameters, metrics, tags, artifacts, etc).\n",
    "- **experiment**: the primary unit of organization and access control for MLflow runs; all MLflow runs belong to an experiment. Experiments let you visualize, search for, and compare runs, as well as download run artifacts and metadata for analysis in other tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe24287",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69a4277",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"ep_prediction_with_random_forest\"\n",
    "mlflow.set_experiment(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c781e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65520651",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tree mlruns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0e20b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat mlruns/1/meta.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d4b577",
   "metadata": {},
   "source": [
    "### Basic logging\n",
    "- Log model hyper-parameters, metric and the model itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d837bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_df, max_depth=2):\n",
    "    with mlflow.start_run():\n",
    "        # Split data\n",
    "        X = train_df[[\"AT\", \"V\", \"AP\", \"RH\"]]\n",
    "        y = train_df[\"PE\"]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        # Fit model\n",
    "        model = RandomForestRegressor(max_depth=max_depth)\n",
    "        model.fit(X_train, y_train)\n",
    "        ## mlflow: log model & its hyper-parameters\n",
    "        mlflow.log_param(\"max_depth\", max_depth)\n",
    "        mlflow.sklearn.log_model(model, \"model\")\n",
    "\n",
    "        # Evaluate the model\n",
    "        y_pred = model.predict(X_test)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "        ## mlflow: log metrics\n",
    "        mlflow.log_metrics({\"testing_mse\": mse, \"testing_rmse\": rmse})\n",
    "        print(f\"Test mse = {mse:.2f}, Test RMSE = {rmse:.2f}, Random forest max depth = {max_depth}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d66d93",
   "metadata": {},
   "source": [
    "- Run the function with mlflow tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fdb811",
   "metadata": {},
   "outputs": [],
   "source": [
    "for max_depth in range(2, 7, 2):\n",
    "    _ = train_model(df, max_depth=max_depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d1d01b",
   "metadata": {},
   "source": [
    "### Visualize experiments with MLflow tracking UI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4143c2",
   "metadata": {},
   "source": [
    "To run the [MLflow Tracking UI](https://www.mlflow.org/docs/latest/tracking.html#tracking-ui), you need to either run the UI with ```mlflow ui``` (needs to be executed from the *notebooks* folder) oor to run an *mlflow server* (will be used in the following section)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb520d80",
   "metadata": {},
   "source": [
    "### Where mlflow saves the data\n",
    "\n",
    "#### Some vocabulary:\n",
    "- **Backend store**: for MLflow entities (runs, parameters, metrics, tags, notes, metadata, etc)\n",
    "- **Artefact store**: for artifacts (files, models, images, in-memory objects, etc)\n",
    "- For more information, [check the official documentation](https://www.mlflow.org/docs/latest/tracking.html#where-runs-are-recorded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1882f490",
   "metadata": {},
   "source": [
    "#### Without prior configuration\n",
    "- When no pror configuration is set, MLflow creates an *mlruns* folder where the data will be saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f728bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ece552",
   "metadata": {},
   "source": [
    "- MLflow created a new folder *mlruns* where it will store the different run informations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a656ec",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!tree mlruns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24d9437",
   "metadata": {},
   "source": [
    "#### With prior configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af4a2b8",
   "metadata": {},
   "source": [
    "- Let's start by shutting down the `mlflow ui` and remvoing the `mlruns` folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07849875",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf mlruns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7778ea2",
   "metadata": {},
   "source": [
    "- Set the **Backend store** to an sqlite database located in */tmp/mlruns.db* and the **Artefact store**  to a folder located in */tmp/mlruns*. For more informations on the different possibilities available (S3, blobstorage, etc) check [the official documentation](https://www.mlflow.org/docs/latest/tracking.html#where-runs-are-recorded).\n",
    "- To run the MLflow server, you need to:\n",
    "    - stop the execution of the UI (`mlflow ui` command)\n",
    "    - execute the following command:\n",
    "        - Linux: ```mlflow server --backend-store-uri sqlite:////tmp/mlruns.db --default-artifact-root /tmp/mlruns```\n",
    "        - Windows: ```mlflow server --backend-store-uri sqlite:///mlruns.db --default-artifact-root mlruns```\n",
    "- Set the tracking uri in the notebook ```mlflow.set_tracking_uri('http://127.0.0.1:5000')```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e7801f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri('http://127.0.0.1:5000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804001b2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create the experiment in the new database\n",
    "experiment_name = \"ep_prediction_with_random_forest\"\n",
    "mlflow.set_experiment(experiment_name=experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4895c0d",
   "metadata": {},
   "source": [
    "### Loggiong with autolog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4856e87",
   "metadata": {},
   "source": [
    "- Autollog will log all the model parameters, training metrics, model binary, etc **BUT not the test metrics**, tthey needd to be logged manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c01a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_df, max_depth=2):\n",
    "    training_timestamp = datetime.now().strftime('%Y-%m-%d, %H:%M:%S')\n",
    "    with mlflow.start_run(run_name=f\"model_{training_timestamp}\"):\n",
    "\n",
    "        mlflow.autolog()\n",
    "        \n",
    "        # Split data\n",
    "        X = train_df[[\"AT\", \"V\", \"AP\", \"RH\"]]\n",
    "        y = train_df[\"PE\"]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        # Fit model\n",
    "        model = RandomForestRegressor(max_depth=max_depth)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Evaluate the model\n",
    "        y_pred = model.predict(X_test)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "        ## mlflow: log metrics\n",
    "        mlflow.log_metrics({\"testing_mse\": mse, \"testing_rmse\": rmse})\n",
    "        print(f\"Test mse = {mse}, Test RMSE = {rmse}, Random forest max depth = {max_depth}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53393ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for max_depth in range(2, 7, 2):\n",
    "    _ = train_model(df, max_depth=max_depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f665b829",
   "metadata": {},
   "source": [
    "### Search runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45dc2181",
   "metadata": {},
   "source": [
    "- [In the UI directly](https://www.mlflow.org/docs/latest/search-syntax.html#search)\n",
    "- [Programmatically with search_runs](https://www.mlflow.org/docs/latest/search-syntax.html#programmatically-searching-runs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919e5ea4",
   "metadata": {},
   "source": [
    "- Get the id of the experiment where we want to search runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34754ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.get_experiment_by_name(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d34ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_id = mlflow.get_experiment_by_name(experiment_name).experiment_id\n",
    "experiment_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7271b9da",
   "metadata": {},
   "source": [
    "- Get all runs for the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29b0471",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.search_runs(experiment_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e29fc6",
   "metadata": {},
   "source": [
    "- Filter runs by max_depth and mse and order them by mse (more information about the filters can be found [here](https://www.mlflow.org/docs/latest/search-runs.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b42457",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "max_depth = 4\n",
    "mlflow.search_runs(\n",
    "    experiment_id,\n",
    "    filter_string=f\"params.max_depth = '{max_depth}' AND metrics.testing_mse <= 40\",\n",
    "    order_by=['metrics.testing_mse asc']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c47eec8",
   "metadata": {},
   "source": [
    "### Load a saved model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96eecc14",
   "metadata": {},
   "source": [
    "- [More informations on other format of model_uri](https://www.mlflow.org/docs/latest/python_api/mlflow.sklearn.html#mlflow.sklearn.load_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349f2799",
   "metadata": {},
   "source": [
    "#### With the result of search_runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fde21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = mlflow.search_runs(\n",
    "    experiment_id,\n",
    "    filter_string=f\"params.max_depth = '{max_depth}' AND metrics.testing_mse <= 40\",\n",
    "    order_by=[\"metrics.testing_mse asc\"]\n",
    ").iloc[0]\n",
    "run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44974719",
   "metadata": {},
   "outputs": [],
   "source": [
    "run.artifact_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022628c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mlflow.sklearn.load_model(model_uri=f\"{run.artifact_uri}/model\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae757c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(df[:5][[\"AT\", \"V\", \"AP\", \"RH\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae061176",
   "metadata": {},
   "source": [
    "- Loading the model independently from the framework with `mlflow.pyfunc.load_model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce629645",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = mlflow.pyfunc.load_model(f\"{run.artifact_uri}/model\")\n",
    "loaded_model.predict(df[:5][[\"AT\", \"V\", \"AP\", \"RH\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6020c68f",
   "metadata": {},
   "source": [
    "- Clear Backend and artifact store (for linux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a44b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /tmp/mlruns /tmp/mlruns.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe8404d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
